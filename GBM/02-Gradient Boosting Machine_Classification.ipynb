{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"02-Gradient Boosting Machine / Classification.ipynb","private_outputs":true,"provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNpUxoM0GJFX8B/7TdqbYUJ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["## **GBM (Classification)**"],"metadata":{"id":"HALms3hgPyYr"}},{"cell_type":"code","source":["# 필요한 기본 package 불러오기\n","import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","import matplotlib.pyplot as plt\n","import matplotlib\n","\n","from sklearn.metrics import accuracy_score\n","from sklearn.metrics import roc_auc_score\n","from sklearn.metrics import mean_absolute_error\n","from sklearn.metrics import mean_squared_error\n","from sklearn.metrics import r2_score\n","import time\n","import warnings\n","warnings.filterwarnings('ignore')"],"metadata":{"id":"I5fbu0vwPx_E"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!git clone https://github.com/KU-DIC/LG_time_series_day07.git"],"metadata":{"id":"idbKJVG0PyAz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### **(1) 마케팅 성공 여부 예측**"],"metadata":{"id":"bsyLF4SKP9qF"}},{"cell_type":"code","source":["'''\n","Bank Marketing Data : 포르투칼 은행의 전화 마케팅 데이터, 전화 마케팅의 성공 여부를 고객의 개인정보를 이용해 예측\n","'''\n","\n","# 데이터 불러오기\n","csv = pd.read_csv(\"/content/LG_time_series_day07/Data_GBM_bank-full.csv\", encoding = \"UTF-8-sig\", sep = \";\")\n","csv.head(10)"],"metadata":{"id":"cKDhaABTPyDz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 데이터 타입(type) 확인\n","csv.dtypes"],"metadata":{"id":"rbAnVGRTPyFs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#전처리 된 데이터 만들기\n","'''\n","연속형 변수 정수형 -> 실수형\n","범주형 변수 -> Dummie Coding\n","'''\n","\n","data = pd.DataFrame()\n","\n","for i, j in enumerate(csv.iloc[:, : -1].dtypes.items()): #데이터의 컬럼과 해당 컬럼의 데이터 타입을 for 문에 입력\n","    #해당 컬럼의 데이터 타입이 연속형(정수형)일 경우,\n","    if j[1] == \"int64\":\n","        #실수형으로 바꾼 컬럼을 data 변수에 추가\n","        data = pd.concat([data, csv.iloc[:, i].astype(float)], axis = 1, sort = False)\n","    #해당 컬럼의 데이터 타입이 범주형일 경우,\n","    else:\n","        #Dummies 코딩 수행\n","        dummies = pd.get_dummies(csv.iloc[:, i])\n","        dummies.columns = [j[0] + \"_\" + k for k in dummies.columns]\n","        #Dummie 코딩한 컬럼을 data에 저장\n","        data = pd.concat([data, dummies], axis = 1, sort = False)\n","\n","#종속 변수 \"yes\"와 \"no\"를 실수형으로 형태 변경\n","data.loc[csv.y == \"yes\", \"y\"] = 1.0\n","data.loc[csv.y == \"no\", \"y\"] = -1.0\n","data.y = data.y.astype(float)"],"metadata":{"id":"9sj7tWKNPyHL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 변경된 데이터 확인 (첫 10개의 instances)\n","data.head(10)"],"metadata":{"id":"9k_rKhBrPyIz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 학습 데이터와 테스트 데이터 구분\n","# 학습 데이터 비율: 0.7, 테스트 데이터 비율: 0.3\n","train_data, test_data = train_test_split(data, train_size = 0.7)\n","\n","# 독립변수(Xs)와 종속변수(Y) 구분\n","train_X = train_data.iloc[:, :-1].reset_index(drop = True) # train_X에 종속변수 제거\n","train_Y = train_data.iloc[:, -1].reset_index(drop = True) # train_Y에 종속변수 따로 저장\n","\n","test_X = test_data.iloc[:, :-1].reset_index(drop = True) # test_X에 종속변수 제거\n","test_Y = test_data.iloc[:, -1].reset_index(drop = True) # test_Y에 종속변수 따로 저장"],"metadata":{"id":"myJWnesYPyKb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# GBM 모델(분류) package 불러오기\n","from sklearn.ensemble import GradientBoostingClassifier\n","\n","# 모델 파라미터 설정\n","model = GradientBoostingClassifier(loss          = \"deviance\",\n","                                   learning_rate = 0.1,\n","                                   n_estimators  = 100,\n","                                   criterion     = \"mse\",\n","                                   max_depth     = 3,\n","                                   min_samples_split = 2,\n","                                   min_samples_leaf  = 1,\n","                                   verbose = 1)\n","\n","# 설정된 모델 파라미터에 데이터 fitting (학습)\n","model.fit(train_X, train_Y)"],"metadata":{"id":"5TyC8HHVPyMT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 학습한 GBM 모델을 통해 테스트 데이터 예측하기\n","\n","# pred 변수에 실제값(y) 추가\n","pred = pd.DataFrame(test_Y)\n","\n","# 생성된 모델로 예측하기 / pred 변수에 예측값 추가\n","pred[\"pred\"] = model.predict(test_X)\n","\n","# 예측 값 확인 (첫 10개 instances)\n","pred.head(10)"],"metadata":{"id":"wpgmnkKWQLCt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Confusion Matrix 생성\n","tab = pd.crosstab(pred.y, pred.pred)\n","\n","#정확도 구하기\n","acc = (tab.iloc[0,0] + tab.iloc[1,1]) / len(test_Y)\n","\n","print(\"Confusion Matrix\")\n","print(tab)\n","print(\"   \")\n","print(\"Acc : \", acc)"],"metadata":{"id":"2woVhZBPQLEc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### **(2) 가입자 이탈 여부 예측**"],"metadata":{"id":"Z-fIB4DSQQeM"}},{"cell_type":"code","source":["'''\n","가입자 이탈/이탈률 dataset : 전체 19개 피처와 1개의 타겟으로 구성 (Categorical feature: State, Area_code, Int.l.Plan, VMail.Plan)\n","\n","타겟명: 'Churn.' / True(1)는 이탈한 고객, False(0)는 이탈하지 않은 고객을 의미함\n","'''\n","\n","# 데이터 불러오기\n","churn = pd.read_csv(\"/content/LG_time_series_day07/Data_GBM_churn.csv\")\n","print('dataset shape:', churn.shape)\n","\n","# 데이터 확인 (첫 3개 instances)\n","churn.head(3)"],"metadata":{"id":"jbyTYj3XQLF1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 데이터 타입(type) 확인\n","churn.info()"],"metadata":{"id":"M6hJbagnQLHU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 데이터 전처리\n","\n","# column name 중 \".\"을 \"_\"으로 변경\n","churn.columns = churn.columns.str.replace(\".\",\"_\")\n","\n","# data중 Area.Code는 지역숫자로 수치적 의미를 갖지 않으므로, category 형태로 변경\n","churn.Area_Code = churn.Area_Code.astype(\"category\")\n","\n","print(churn['Churn_'].value_counts())\n","\n","unsatisfied_cnt = churn[churn['Churn_'] == \"True.\" ].Churn_.count()\n","total_cnt = churn.Churn_.count()\n","\n","print('\\n\\n unsatisfied 비율은 {0:.3f}'.format((unsatisfied_cnt / total_cnt)))"],"metadata":{"id":"gzzwhNIaQcPl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 변경된 데이터 타입(type) 확인\n","churn.info()"],"metadata":{"id":"fpO1UUlAQch0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 독립변수(Xs)와 종속변수(Y) 구분\n","X_features = churn.iloc[:, :-1]\n","y_labels = churn.iloc[:, -1]\n","\n","# 타겟 변수에 대해 불만족한 고객 ('True.')을 1로, 나머지는 0으로 해서 최종적으로 binary class {1, 0}로 변경\n","y_labels = np.where(y_labels == \"True.\", 1, 0)\n","y_labels = pd.Series(y_labels)\n","\n","print('feature shape:{0}'.format(X_features.shape))"],"metadata":{"id":"0tuT-TrGQcjk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# object 타입을 category로 변경\n","for col in X_features.columns:\n","    if X_features[col].dtypes == \"O\":\n","        X_features[col] = X_features[col].astype('category')\n","\n","# 데이터 타입(type) 확인\n","X_features.info()"],"metadata":{"id":"5IklUK0WQclP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# GBM에서 categorical feature에 대해 one-hot encoding 진행\n","def onehot(data, feature):\n","    return pd.concat([data, pd.get_dummies(data[feature], prefix=feature)], axis=1).drop([feature], axis=1)\n","\n","# 다음 4가지 categorical feature에 대해 one-hot encoding을 진행 후 기존 X_feature에 결합\n","cate_list = ['State', 'Area_Code', 'Int_l_Plan', 'VMail_Plan']\n","for i in range(len(cate_list)):\n","    X_features = onehot(X_features, cate_list[i])"],"metadata":{"id":"Gq2rb7SSQcms"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 추가된 feature 확인\n","X_features.info()"],"metadata":{"id":"yv5pLsy6QcoU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 학습 데이터와 테스트 데이터 구분\n","# 학습 데이터 비율: 0.8, 테스트 데이터 비율: 0.2\n","X_train, X_test, y_train, y_test = train_test_split(X_features, y_labels, test_size=0.2, random_state=0)\n","train_cnt = y_train.count()\n","test_cnt = y_test.count()\n","print('학습 세트 Shape:{0}, 테스트 세트 Shape:{1}'.format(X_train.shape , X_test.shape))\n","\n","print(' 학습 세트 레이블 값 분포 비율')\n","print(y_train.value_counts()/train_cnt)\n","print('\\n 테스트 세트 레이블 값 분포 비율')\n","print(y_test.value_counts()/test_cnt)"],"metadata":{"id":"PGjQwJJ0QcrT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# GBM 모델 package 불러오기\n","from sklearn.ensemble import GradientBoostingClassifier\n","\n","# GBM 수행 시간 측정을 위함. 시작 시간 설정\n","start_time = time.time()\n","\n","# 모델 생성 및 train data로 fitting (학습) 진행\n","gb_clf = GradientBoostingClassifier(random_state=0)\n","gb_clf.fit(X_train , y_train)\n","\n","# GBM 실험 종료에 대한 시간 측정\n","gb_time = time.time() - start_time"],"metadata":{"id":"PAROqpn-QjoN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 학습 완료된 GBM 모델을 통해 테스트 데이터 예측\n","gb_pred = gb_clf.predict(X_test)\n","\n","# 예측 값과 실제 값 간의 비교를 통해, 정확도(차이) 계산\n","gb_accuracy = accuracy_score(y_test, gb_pred)\n","\n","print('GBM 정확도: {0:.4f}'.format(gb_accuracy))\n","print(\"GBM 수행 시간: {0:.2f} 초 \".format(gb_time))\n","\n","gb_roc_score = roc_auc_score(y_test, gb_clf.predict_proba(X_test)[:,1], average='macro')\n","print('ROC AUC: {0:.4f}'.format(gb_roc_score))"],"metadata":{"id":"TyYWCkpZQjp7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 최적 hyper parameter를 찾기 위해 GridSearchCV 실행\n","from sklearn.model_selection import GridSearchCV\n","\n","params = {\n","    'n_estimators':[100, 500],\n","    'learning_rate' : [ 0.05, 0.1]\n","}\n","\n","gb_grid_cv = GridSearchCV(gb_clf , param_grid=params , cv=2 ,verbose=1, n_jobs=-1)\n","gb_grid_cv.fit(X_train , y_train)\n","print('최적 하이퍼 파라미터:\\n', gb_grid_cv.best_params_)\n","print('최고 예측 정확도: {0:.4f}'.format(gb_grid_cv.best_score_))"],"metadata":{"id":"T_gw8YSeQjrc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# GridSearchCV를 이용하여 최적으로 학습된 estimator로 예측 수행\n","gb_pred = gb_grid_cv.best_estimator_.predict(X_test)\n","gb_accuracy = accuracy_score(y_test, gb_pred)\n","print('GBM 정확도: {0:.4f}'.format(gb_accuracy))\n","\n","gb_grid_cv_roc_score = roc_auc_score(y_test, gb_grid_cv.predict_proba(X_test)[:,1],average='macro')\n","print('GBM ROC AUC: {0:.4f}'.format(gb_grid_cv_roc_score))"],"metadata":{"id":"GgqdaIURQju7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"76HASBsnQjxE"},"execution_count":null,"outputs":[]}]}